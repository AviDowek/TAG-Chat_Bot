{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9c109a",
   "metadata": {},
   "source": [
    "This code loads the data file using langchain and passes it through the OpenAI API for emebdding.  It is then stored in a FAISS index.    The emebedding time depends on the file passed, but is usually <15 minutes.    The data file is created in a seperate script that scrapes the Wiki and Slack Channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf5b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import SlackDirectoryLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# OpenAI API Key  (Need to change to an envo var)\n",
    "key = ''\n",
    "\n",
    "# Load and split the Dataset\n",
    "loader1 = PyPDFLoader(\"path/to/file/All_Data_PDF.pdf\")\n",
    "pages1 = loader1.load_and_split()\n",
    "\n",
    "#loader2 = SlackDirectoryLoader('C:/Users/avido/OneDrive/Desktop/Chamor/TAG Support Slack export Sep 21 2016 - Sep 18 2023.zip')\n",
    "#pages2=loader2.load_and_split()\n",
    "\n",
    "pages=pages1\n",
    "\n",
    "# Create Index and Embeddings\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=key))\n",
    "\n",
    "print('Indexed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee73f8a",
   "metadata": {},
   "source": [
    "This script creates a Flask server which can then be accessed with a redirect URL from ngrok.  The Bot ID and Channel ID are currently hard coded for testing purposes.   There are a few prints and various, crucial checkpoints.   The script also checks the message time-stamp.  This was included due to an issue with the Bot looping through all mentions and responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import slack\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "from datetime import datetime, timedelta\n",
    "#!pip install slackeventsapi\n",
    "\n",
    "from flask import Flask\n",
    "import slack\n",
    "from slackeventsapi import SlackEventAdapter\n",
    "from slack_sdk import WebClient\n",
    "import os\n",
    "\n",
    "# Initialize the Slack API client with the hardcoded token- Need to switch to envo\n",
    "client = WebClient(token=\"\")\n",
    "\n",
    "app=Flask(__name__)\n",
    "\n",
    "#Assign a URL extension and pass the Client Secret tio authenticate\n",
    "slack_event_adapter=SlackEventAdapter('','/slack/events',app)\n",
    "\n",
    "\n",
    "#For future use- retrives bot id\n",
    "bot_id=client.api_call(\"auth.test\")['user_id']\n",
    "\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=key)\n",
    "\n",
    "# Initialize the MultiQueryRetriever\n",
    "retriever = MultiQueryRetriever.from_llm(retriever=faiss_index.as_retriever(), llm=llm)\n",
    "\n",
    "# Create a QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "\n",
    "# Define a function to process messages\n",
    "def process_message(message):\n",
    "    \n",
    "    #Checkpoint\n",
    "    print('here')\n",
    "    # Split the message into smaller chunks to account for token limits\n",
    "    max_tokens = 4000  # Under context length supported by the model\n",
    "    chunked_message = \"\"\n",
    "    chunked_messages = []\n",
    "\n",
    "    for word in message.split():\n",
    "        if len(chunked_message) + len(word) + 1 >= max_tokens:\n",
    "            if chunked_message:\n",
    "                chunked_messages.append(chunked_message)\n",
    "            chunked_message = \"\"\n",
    "        if chunked_message:\n",
    "            chunked_message += \" \"\n",
    "        chunked_message += word\n",
    "\n",
    "    if chunked_message:\n",
    "        chunked_messages.append(chunked_message)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunked_message in chunked_messages:\n",
    "        result = qa_chain({'query': chunked_message})\n",
    "        answer = result['result']\n",
    "        response += answer + \" \"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "@slack_event_adapter.on('message')\n",
    "def send_message(payload):\n",
    "    event=payload.get('event',{})\n",
    "    channel_id=''   #Hard-coded to only allow messages from bot-testing channel\n",
    "    user_id=event.get('user')\n",
    "    text=event.get('text')\n",
    "    message_ts = float(event.get('ts'))  # Convert timestamp to float\n",
    "    \n",
    "    # Define a threshold for considering messages (needed to prevent bot responding in a loop to all previous messages)\n",
    "    threshold_time = datetime.now() - timedelta(seconds=2)\n",
    "    threshold_ts = threshold_time.timestamp()\n",
    "\n",
    "    \n",
    "    if user_id !=bot_id:  #check that message is not from Bot (not really needed as only listens for @bot, but may need)\n",
    "       \n",
    "        if f'<@{bot_id}>' in event['text'] and message_ts >= threshold_ts:\n",
    "            #checkpoint\n",
    "            print('rerun')\n",
    "            time.sleep(2)\n",
    "            \n",
    "            #pass text to function to get answer\n",
    "            response = process_message(text) \n",
    "            \n",
    "            #send response to slack\n",
    "            client.chat_postMessage(channel=channel_id, text=response)\n",
    "            return\n",
    "           \n",
    "        \n",
    "    \n",
    "    time.sleep(1)  # Add a 1-second delay between API calls to avoid rate limiting     \n",
    "\n",
    "        \n",
    "# Start listening for messages from Slack\n",
    "if __name__ == \"__main__\":\n",
    "    #Run flask.  Using debug=true throws an error- need to check\n",
    "    app.run()     \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
